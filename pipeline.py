"""Core audio -> score pipeline for BTT MVP."""

from __future__ import annotations

import glob
import shlex
import subprocess
import warnings
from pathlib import Path

from pydub import AudioSegment

from config import (
    DEMUCS_MODEL,
    DOWNLOADS_DIR,
    INSTRUMENT_SPECS,
    MUSESCORE_CMD,
    OUTPUT_DIR,
    TEMP_DIR,
    YOUTUBE_DOMAINS,
)
from utils import (
    classify_audio_source,
    create_disclaimer_text,
    sanitize_filename,
    validate_single_video_youtube_url,
)


def _run(cmd: list[str]) -> None:
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        rendered = " ".join(shlex.quote(part) for part in cmd)
        raise RuntimeError(
            f"Command failed ({result.returncode}): {rendered}\n{result.stderr.strip()}"
        )


def _ensure_dirs() -> None:
    TEMP_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    DOWNLOADS_DIR.mkdir(parents=True, exist_ok=True)


def download_or_convert_audio(source: str, run_dir: Path | None = None) -> str:
    """Convert local audio file or YouTube URL into normalized wav."""
    _ensure_dirs()
    workdir = run_dir or TEMP_DIR
    workdir.mkdir(parents=True, exist_ok=True)
    source = source.strip()
    output_wav = workdir / "input_normalized.wav"
    source_kind = classify_audio_source(source, YOUTUBE_DOMAINS)

    if source_kind == "youtube_url":
        youtube_error = validate_single_video_youtube_url(source, YOUTUBE_DOMAINS)
        if youtube_error:
            raise ValueError(youtube_error)
        yt_template = str(workdir / "youtube_input.%(ext)s")
        _run(
            [
                "yt-dlp",
                "--no-playlist",
                "-x",
                "--audio-format",
                "wav",
                "-o",
                yt_template,
                source,
            ]
        )
        yt_files = sorted(glob.glob(str(workdir / "youtube_input.*")))
        if not yt_files:
            raise RuntimeError("yt-dlp did not produce an audio file.")
        audio = AudioSegment.from_file(yt_files[0])
    else:
        if source_kind == "remote_url":
            raise ValueError("Only single-video YouTube URLs are supported for remote input.")
        input_path = Path(source)
        if not input_path.exists():
            raise FileNotFoundError(f"Audio source does not exist: {source}")
        audio = AudioSegment.from_file(str(input_path))

    audio = audio.set_channels(2).set_frame_rate(44100)
    audio.export(str(output_wav), format="wav")
    return str(output_wav)


def separate_stems(wav_path: str, run_dir: Path | None = None) -> dict[str, str]:
    """Run Demucs separation and return stem-name -> wav path."""
    _ensure_dirs()
    workdir = run_dir or TEMP_DIR
    wav = Path(wav_path)
    if not wav.exists():
        raise FileNotFoundError(f"Input wav missing: {wav_path}")

    demucs_out = workdir / "demucs"
    _run(["demucs", "-n", DEMUCS_MODEL, "-o", str(demucs_out), str(wav)])

    stem_root = demucs_out / DEMUCS_MODEL / wav.stem
    if not stem_root.exists():
        raise RuntimeError(f"Demucs output folder missing: {stem_root}")

    stems: dict[str, str] = {}
    for stem_file in sorted(stem_root.glob("*.wav")):
        stems[stem_file.stem] = str(stem_file)
    if not stems:
        raise RuntimeError("No stems were generated by Demucs.")
    return stems


def transcribe_to_midi(stems: dict[str, str], run_dir: Path | None = None) -> dict[str, str]:
    """Run basic-pitch CLI on each stem file and return stem-name -> midi path."""
    _ensure_dirs()
    workdir = run_dir or TEMP_DIR
    midi_root = workdir / "midi"
    midi_root.mkdir(parents=True, exist_ok=True)

    outputs: dict[str, str] = {}
    for stem_name, stem_path in stems.items():
        stem_dir = midi_root / sanitize_filename(stem_name)
        stem_dir.mkdir(parents=True, exist_ok=True)
        _run(["basic-pitch", str(stem_dir), str(stem_path)])
        midi_candidates = sorted(stem_dir.glob("*.mid")) + sorted(stem_dir.glob("*.midi"))
        if not midi_candidates:
            raise RuntimeError(f"No MIDI produced for stem: {stem_name}")
        outputs[stem_name] = str(midi_candidates[0])
    return outputs


def _grid_to_divisor(grid: str) -> int:
    mapping = {"1/4": 1, "1/8": 2, "1/16": 4}
    return mapping.get(grid, 2)


def _suppress_known_music21_warnings() -> None:
    """Mute noisy non-fatal music21 warnings that clutter Streamlit logs."""
    try:
        from music21 import beam

        beam.environLocal["warnings"] = 0
    except Exception:
        pass
    warnings.filterwarnings(
        "ignore",
        message=r"cannot access qLenPos .*",
        category=UserWarning,
    )
    warnings.filterwarnings(
        "ignore",
        message=r"Cannot put in an element with a missing voice tag .*",
        category=UserWarning,
    )


def _simplify_part(part_stream, options: dict) -> None:
    divisor = _grid_to_divisor(options.get("quantize_grid", "1/8"))
    min_duration = float(options.get("min_note_duration_beats", 0.25))
    density_threshold = int(options.get("density_threshold", 6))

    part_stream.quantize(
        quarterLengthDivisors=(divisor,),
        processOffsets=True,
        processDurations=True,
        inPlace=True,
        recurse=True,
    )

    # Work on stream-owned note/rest objects, not a flattened copy.
    # Removing elements from flattened views does not reliably mutate the source stream.
    flattened = part_stream.recurse()
    bucket_counts: dict[int, int] = {}
    for element in list(flattened.notesAndRests):
        if getattr(element, "isNote", False) or getattr(element, "isChord", False):
            if float(element.duration.quarterLength) < min_duration:
                if element.activeSite is not None:
                    element.activeSite.remove(element)
                continue
            bucket = int(float(element.getOffsetInHierarchy(part_stream)))
            bucket_counts[bucket] = bucket_counts.get(bucket, 0) + 1
            if bucket_counts[bucket] > density_threshold:
                if element.activeSite is not None:
                    element.activeSite.remove(element)


def _is_beginner_profile(options: dict) -> bool:
    profile = str(options.get("profile", "")).strip()
    return profile in {"Beginner", "Aggressive"}


def _iter_melodic_notes(part_stream):
    """Yield note-like elements in temporal order for melodic post-processing."""
    for element in part_stream.recurse().notes:
        if getattr(element, "isChord", False):
            yield element
        elif getattr(element, "isNote", False):
            yield element


def _primary_pitch_midi(element) -> int | None:
    if getattr(element, "isChord", False):
        pitches = list(getattr(element, "pitches", []) or [])
        if not pitches:
            return None
        return int(min(p.midi for p in pitches))
    if getattr(element, "isNote", False):
        pitch_obj = getattr(element, "pitch", None)
        if pitch_obj is None:
            return None
        return int(pitch_obj.midi)
    return None


def _set_element_to_midi(element, midi_value: int) -> None:
    from music21 import pitch

    new_pitch = pitch.Pitch()
    new_pitch.midi = int(midi_value)
    if getattr(element, "isChord", False):
        element.pitches = (new_pitch,)
    elif getattr(element, "isNote", False):
        element.pitch = new_pitch


def _nearest_scale_midi(target_midi: int, allowed_pitch_classes: set[int]) -> int:
    candidates: list[int] = []
    for delta in range(-2, 3):
        candidate = int(target_midi + delta)
        if candidate % 12 in allowed_pitch_classes:
            candidates.append(candidate)
    if not candidates:
        return target_midi
    return min(candidates, key=lambda value: abs(value - target_midi))


def _playability_metrics(part_stream) -> dict[str, float]:
    note_elements = list(_iter_melodic_notes(part_stream))
    midi_line = [value for value in (_primary_pitch_midi(n) for n in note_elements) if value is not None]
    note_count = len(note_elements)
    if note_count == 0:
        return {
            "note_count": 0.0,
            "accidental_density": 0.0,
            "large_leap_rate": 0.0,
            "short_note_rate": 0.0,
        }

    accidental_count = 0
    short_count = 0
    for element in note_elements:
        if float(element.duration.quarterLength) <= 0.5:
            short_count += 1
        if getattr(element, "isChord", False):
            pitches = list(getattr(element, "pitches", []) or [])
            accidental_count += sum(1 for p in pitches if p.accidental is not None)
        elif getattr(element, "isNote", False):
            pitch_obj = getattr(element, "pitch", None)
            if pitch_obj is not None and pitch_obj.accidental is not None:
                accidental_count += 1

    leaps = [abs(curr - prev) for prev, curr in zip(midi_line, midi_line[1:])]
    large_leap_count = sum(1 for size in leaps if size >= 8)

    return {
        "note_count": float(note_count),
        "accidental_density": float(accidental_count / note_count),
        "large_leap_rate": float(large_leap_count / max(1, len(leaps))),
        "short_note_rate": float(short_count / note_count),
    }


def _apply_beginner_melody_filter(part_stream) -> dict[str, float]:
    """Apply additional melody-aware cleanup for beginner readability."""
    from music21 import key

    notes = list(_iter_melodic_notes(part_stream))
    if not notes:
        return _playability_metrics(part_stream)

    # Remove very short ornament-like events.
    for element in list(notes):
        if float(element.duration.quarterLength) < 0.5 and element.activeSite is not None:
            element.activeSite.remove(element)

    notes = list(_iter_melodic_notes(part_stream))
    if not notes:
        return _playability_metrics(part_stream)

    # Favor diatonic pitches of the local key to reduce accidental noise.
    try:
        analyzed_key = part_stream.analyze("key")
    except Exception:
        analyzed_key = key.Key("C")
    allowed_pitch_classes = set(int(p.pitchClass) for p in analyzed_key.getScale().pitches)
    for element in notes:
        base = _primary_pitch_midi(element)
        if base is None:
            continue
        snapped = _nearest_scale_midi(base, allowed_pitch_classes)
        _set_element_to_midi(element, snapped)

    # Clamp leaps by octave-folding toward the previous pitch.
    notes = list(_iter_melodic_notes(part_stream))
    previous_midi: int | None = None
    for element in notes:
        current_midi = _primary_pitch_midi(element)
        if current_midi is None:
            continue
        if previous_midi is not None:
            while current_midi - previous_midi > 7:
                current_midi -= 12
            while previous_midi - current_midi > 7:
                current_midi += 12
            _set_element_to_midi(element, current_midi)
        previous_midi = current_midi

    return _playability_metrics(part_stream)


def _woodwind_range_midi(instrument_name: str) -> tuple[int, int]:
    """Return conservative concert-pitch MIDI bounds for student woodwind notation."""
    name = str(instrument_name or "")
    if "Clarinet" in name:
        # Bb clarinet (concert): roughly D3-Bb5 for middle-school readability.
        return (50, 82)
    if "Alto Sax" in name:
        # Alto sax (concert): roughly Db3-A5 in student-friendly range.
        return (49, 81)
    if "Tenor Sax" in name:
        return (44, 74)
    if "Baritone Sax" in name:
        return (36, 67)
    if "Sax" in name:
        return (49, 81)
    if "Flute" in name:
        return (60, 88)
    if "Oboe" in name:
        return (58, 86)
    return (48, 84)


def _is_woodwind_target(instrument_name: str) -> bool:
    name = str(instrument_name or "")
    return any(token in name for token in ("Clarinet", "Sax", "Flute", "Oboe", "Bassoon"))


def _is_percussion_target(instrument_name: str) -> bool:
    name = str(instrument_name or "")
    return any(token in name for token in ("Snare", "Bass Drum", "Percussion", "Auxiliary", "Timpani"))


def _is_low_brass_target(instrument_name: str) -> bool:
    name = str(instrument_name or "")
    return any(token in name for token in ("Tuba", "Trombone", "Euphonium", "Bassoon", "Bass Clarinet"))


def _instrument_range_midi(instrument_name: str) -> tuple[int, int]:
    if _is_woodwind_target(instrument_name):
        return _woodwind_range_midi(instrument_name)
    name = str(instrument_name or "")
    if "Tuba" in name:
        return (28, 58)
    if "Trombone" in name:
        return (40, 70)
    if "Euphonium" in name:
        return (40, 72)
    if "Bassoon" in name:
        return (34, 69)
    return (36, 84)


def _written_range_midi(instrument_name: str) -> tuple[int, int] | None:
    """Return student-friendly written ranges for transposed part exports."""
    name = str(instrument_name or "")
    if "Bb Clarinet" in name or "Clarinet" in name:
        return (52, 84)  # E3 to C6 (written)
    if "Alto Sax" in name:
        return (57, 79)  # A3 to G5 (written, classroom-safe)
    if "Tenor Sax" in name:
        return (50, 76)
    if "Baritone Sax" in name:
        return (45, 72)
    return None


def _clamp_written_part_range(part_stream, instrument_name: str) -> None:
    """Fold written notes by octave into a student-friendly written range."""
    limits = _written_range_midi(instrument_name)
    if limits is None:
        return
    min_midi, max_midi = limits
    for element in list(part_stream.recurse().notes):
        if not getattr(element, "isNote", False):
            continue
        pitch_obj = getattr(element, "pitch", None)
        if pitch_obj is None:
            continue
        midi_value = int(pitch_obj.midi)
        while midi_value > max_midi:
            midi_value -= 12
        while midi_value < min_midi:
            midi_value += 12
        pitch_obj.midi = int(max(min_midi, min(max_midi, midi_value)))


def _sanitize_woodwind_melody(part_stream, instrument_name: str, options: dict) -> None:
    """Apply contour-aware monophony and range-safe cleanup for woodwind parts."""
    from music21 import chord, note, pitch

    grid = str(options.get("quantize_grid", "1/8"))
    grid_step = {"1/4": 1.0, "1/8": 0.5, "1/16": 0.25}.get(grid, 0.5)
    min_duration = max(float(options.get("min_note_duration_beats", 0.25)), grid_step)
    min_midi, max_midi = _woodwind_range_midi(instrument_name)
    center_midi = (min_midi + max_midi) / 2.0

    # Group notes/chords into a sliding time window to collapse near-overlaps.
    grouped: dict[float, list] = {}
    for element in list(part_stream.recurse().notes):
        try:
            offset = float(element.getOffsetInHierarchy(part_stream))
        except Exception:
            continue
        bucket = round(offset / grid_step) * grid_step
        grouped.setdefault(bucket, []).append(element)

    if not grouped:
        return

    previous_midi: int | None = None
    for offset in sorted(grouped.keys()):
        elements = grouped[offset]
        if not elements:
            continue
        anchor = elements[0]
        raw_candidates: list[int] = []
        durations: list[float] = []
        for element in elements:
            durations.append(float(element.duration.quarterLength))
            if isinstance(element, chord.Chord):
                raw_candidates.extend(int(p.midi) for p in element.pitches)
            elif isinstance(element, note.Note) and getattr(element, "pitch", None) is not None:
                raw_candidates.append(int(element.pitch.midi))

        raw_candidates = sorted(set(raw_candidates))
        in_range = [m for m in raw_candidates if min_midi <= m <= max_midi]
        candidates = in_range if in_range else raw_candidates

        duration = max(durations) if durations else min_duration
        duration = max(min_duration, round(duration / grid_step) * grid_step)

        if candidates:
            if previous_midi is None:
                chosen = min(candidates, key=lambda m: abs(m - center_midi))
            else:
                chosen = min(candidates, key=lambda m: abs(m - previous_midi))
            chosen = max(min_midi, min(max_midi, int(chosen)))
            if previous_midi is not None:
                while chosen - previous_midi > 7:
                    chosen -= 12
                while previous_midi - chosen > 7:
                    chosen += 12
                chosen = max(min_midi, min(max_midi, int(chosen)))

            if isinstance(anchor, chord.Chord):
                replacement = note.Note()
                replacement.quarterLength = duration
                new_pitch = pitch.Pitch()
                new_pitch.midi = int(chosen)
                replacement.pitch = new_pitch
                if anchor.activeSite is not None:
                    anchor.activeSite.replace(anchor, replacement)
                    anchor = replacement
            elif isinstance(anchor, note.Note):
                new_pitch = pitch.Pitch()
                new_pitch.midi = int(chosen)
                anchor.pitch = new_pitch
                anchor.quarterLength = duration
            previous_midi = int(chosen)
        else:
            replacement_rest = note.Rest(quarterLength=duration)
            if anchor.activeSite is not None:
                anchor.activeSite.replace(anchor, replacement_rest)

        for extra in elements[1:]:
            try:
                if extra.activeSite is not None:
                    extra.activeSite.remove(extra)
            except Exception:
                pass


def _sanitize_single_line_part(part_stream, instrument_name: str, options: dict) -> None:
    """Collapse dense polyphony into a playable single line for monophonic parts."""
    from music21 import chord, note, pitch

    grid = str(options.get("quantize_grid", "1/8"))
    grid_step = {"1/4": 1.0, "1/8": 0.5, "1/16": 0.25}.get(grid, 0.5)
    min_duration = max(float(options.get("min_note_duration_beats", 0.25)), grid_step)
    min_midi, max_midi = _instrument_range_midi(instrument_name)
    center_midi = (min_midi + max_midi) / 2.0
    low_register = _is_low_brass_target(instrument_name)

    grouped: dict[float, list] = {}
    for element in list(part_stream.recurse().notes):
        try:
            offset = float(element.getOffsetInHierarchy(part_stream))
        except Exception:
            continue
        bucket = round(offset / grid_step) * grid_step
        grouped.setdefault(bucket, []).append(element)

    previous_midi: int | None = None
    for offset in sorted(grouped.keys()):
        elements = grouped[offset]
        if not elements:
            continue
        anchor = elements[0]
        durations: list[float] = []
        candidates: list[int] = []
        for element in elements:
            durations.append(float(element.duration.quarterLength))
            if isinstance(element, chord.Chord):
                candidates.extend(int(p.midi) for p in element.pitches)
            elif isinstance(element, note.Note) and getattr(element, "pitch", None) is not None:
                candidates.append(int(element.pitch.midi))

        in_range = [m for m in sorted(set(candidates)) if min_midi <= m <= max_midi]
        if not in_range:
            in_range = sorted(set(candidates))
        duration = max(durations) if durations else min_duration
        duration = max(min_duration, round(duration / grid_step) * grid_step)

        if in_range:
            if previous_midi is None:
                chosen = min(in_range, key=lambda m: abs(m - center_midi))
            else:
                chosen = min(in_range, key=lambda m: abs(m - previous_midi))
            if low_register:
                anchor_midi = previous_midi if previous_midi is not None else int(center_midi)
                chosen = min(in_range, key=lambda m: (abs(m - anchor_midi), m))
            chosen = max(min_midi, min(max_midi, int(chosen)))
            if previous_midi is not None:
                while chosen - previous_midi > 9:
                    chosen -= 12
                while previous_midi - chosen > 9:
                    chosen += 12
                chosen = max(min_midi, min(max_midi, int(chosen)))
            if isinstance(anchor, chord.Chord):
                replacement = note.Note()
                replacement.quarterLength = duration
                p = pitch.Pitch()
                p.midi = int(chosen)
                replacement.pitch = p
                if anchor.activeSite is not None:
                    anchor.activeSite.replace(anchor, replacement)
            elif isinstance(anchor, note.Note):
                p = pitch.Pitch()
                p.midi = int(chosen)
                anchor.pitch = p
                anchor.quarterLength = duration
            previous_midi = int(chosen)
        else:
            replacement_rest = note.Rest(quarterLength=duration)
            if anchor.activeSite is not None:
                anchor.activeSite.replace(anchor, replacement_rest)

        for extra in elements[1:]:
            try:
                if extra.activeSite is not None:
                    extra.activeSite.remove(extra)
            except Exception:
                pass


def _sanitize_percussion_part(part_stream, options: dict) -> None:
    """Map noisy pitched percussion transcription into a single unpitched timeline."""
    from music21 import chord, note, pitch

    grid = str(options.get("quantize_grid", "1/8"))
    grid_step = {"1/4": 1.0, "1/8": 0.5, "1/16": 0.25}.get(grid, 0.5)
    min_duration = max(float(options.get("min_note_duration_beats", 0.25)), grid_step)
    grouped: dict[float, list] = {}

    for element in list(part_stream.recurse().notes):
        try:
            offset = float(element.getOffsetInHierarchy(part_stream))
        except Exception:
            continue
        bucket = round(offset / grid_step) * grid_step
        grouped.setdefault(bucket, []).append(element)

    for offset in sorted(grouped.keys()):
        elements = grouped[offset]
        if not elements:
            continue
        anchor = elements[0]
        durations = [float(element.duration.quarterLength) for element in elements]
        duration = max(durations) if durations else min_duration
        duration = max(min_duration, round(duration / grid_step) * grid_step)

        if isinstance(anchor, chord.Chord):
            replacement = note.Note()
            replacement.pitch = pitch.Pitch("C5")
            replacement.quarterLength = duration
            if anchor.activeSite is not None:
                anchor.activeSite.replace(anchor, replacement)
        elif isinstance(anchor, note.Note):
            anchor.pitch = pitch.Pitch("C5")
            anchor.quarterLength = duration

        for extra in elements[1:]:
            try:
                if extra.activeSite is not None:
                    extra.activeSite.remove(extra)
            except Exception:
                pass


def _tighten_monophonic_timeline(part_stream, grid: str) -> None:
    """Rebuild note timeline on a strict grid to eliminate overlap drift."""
    import copy

    from music21 import chord, note, pitch, stream

    grid_step = {"1/4": 1.0, "1/8": 0.5, "1/16": 0.25}.get(str(grid), 0.5)
    events: list[tuple[float, float, int | None]] = []

    for element in list(part_stream.recurse().notes):
        try:
            raw_offset = float(element.getOffsetInHierarchy(part_stream))
        except Exception:
            continue
        offset = round(raw_offset / grid_step) * grid_step
        duration = max(grid_step, round(float(element.duration.quarterLength) / grid_step) * grid_step)
        midi_value: int | None = None
        if isinstance(element, note.Note) and getattr(element, "pitch", None) is not None:
            midi_value = int(element.pitch.midi)
        elif isinstance(element, chord.Chord):
            pitches = [int(p.midi) for p in element.pitches]
            if pitches:
                midi_value = max(pitches)
        events.append((offset, duration, midi_value))

    if not events:
        return

    events.sort(key=lambda item: item[0])
    normalized: list[tuple[float, float, int | None]] = []
    for idx, (offset, duration, midi_value) in enumerate(events):
        next_offset = events[idx + 1][0] if idx + 1 < len(events) else None
        if next_offset is not None:
            duration = min(duration, max(grid_step, next_offset - offset))
        if normalized and abs(normalized[-1][0] - offset) < 1e-6:
            # Keep only one event per grid bucket; prefer pitched note when available.
            prev_offset, prev_duration, prev_midi = normalized[-1]
            winner_midi = midi_value if midi_value is not None else prev_midi
            winner_duration = max(prev_duration, duration)
            normalized[-1] = (prev_offset, winner_duration, winner_midi)
            continue
        normalized.append((offset, duration, midi_value))

    replacement = stream.Part()
    for offset, duration, midi_value in normalized:
        if midi_value is None:
            replacement.insert(offset, note.Rest(quarterLength=duration))
            continue
        p = pitch.Pitch()
        p.midi = midi_value
        n = note.Note()
        n.pitch = p
        n.quarterLength = duration
        replacement.insert(offset, n)

    for element in list(part_stream.notesAndRests):
        try:
            part_stream.remove(element)
        except Exception:
            pass
    for element in list(part_stream.recurse().getElementsByClass(stream.Measure)):
        try:
            part_stream.remove(element)
        except Exception:
            pass
    for element in list(replacement.notesAndRests):
        try:
            offset = float(element.getOffsetInHierarchy(replacement))
        except Exception:
            offset = 0.0
        part_stream.insert(offset, copy.deepcopy(element))


def _force_fixed_percussion_pitch(part_stream, pitch_name: str = "C5") -> None:
    """Ensure unpitched percussion displays as a single staff position."""
    from music21 import note, pitch

    for element in list(part_stream.recurse().notes):
        if isinstance(element, note.Note):
            element.pitch = pitch.Pitch(pitch_name)


def _insert_guarded_key_signature(part_stream) -> None:
    """Insert detected key only when it likely reduces inline accidental clutter."""
    from music21 import key

    metrics = _playability_metrics(part_stream)
    if float(metrics.get("accidental_density", 0.0)) < 0.18:
        return
    try:
        detected = part_stream.analyze("key")
    except Exception:
        return
    if not isinstance(detected, key.Key):
        return
    if abs(int(detected.sharps)) > 4:
        return
    for existing in list(part_stream.recurse().getElementsByClass(key.KeySignature)):
        try:
            existing.activeSite.remove(existing)
        except Exception:
            pass
    part_stream.insert(0, key.KeySignature(int(detected.sharps)))


def _flatten_part_to_primary_voice(part_stream) -> None:
    """Collapse measures to a single primary voice to avoid overlapping timelines."""
    import copy

    from music21 import stream

    for measure in list(part_stream.recurse().getElementsByClass(stream.Measure)):
        voices = list(measure.getElementsByClass(stream.Voice))
        if len(voices) <= 1:
            continue
        primary = voices[0]
        primary_events: list[tuple[float, object]] = []
        for element in list(primary.notesAndRests):
            try:
                offset = float(element.getOffsetInHierarchy(measure))
            except Exception:
                continue
            primary_events.append((offset, copy.deepcopy(element)))

        for element in list(measure.notesAndRests):
            try:
                measure.remove(element)
            except Exception:
                pass
        for voice in voices:
            try:
                measure.remove(voice)
            except Exception:
                pass
        for offset, element in primary_events:
            measure.insert(offset, element)


def _rebalance_measure_durations(part_stream) -> None:
    """Ensure each measure duration matches the active time signature bar duration."""
    from music21 import meter, note, stream

    for measure in list(part_stream.recurse().getElementsByClass(stream.Measure)):
        signatures = measure.getTimeSignatures(returnDefault=True)
        ts = signatures[0] if signatures else meter.TimeSignature("4/4")
        target = float(ts.barDuration.quarterLength)
        current = float(measure.duration.quarterLength)

        if current < target - 1e-6:
            measure.insert(current, note.Rest(quarterLength=(target - current)))
            continue

        overflow = current - target
        if overflow <= 1e-6:
            continue
        tail = sorted(
            list(measure.notesAndRests),
            key=lambda item: float(item.getOffsetInHierarchy(measure)),
            reverse=True,
        )
        for element in tail:
            if overflow <= 1e-6:
                break
            duration = float(element.duration.quarterLength)
            if duration <= overflow + 1e-6:
                try:
                    measure.remove(element)
                except Exception:
                    pass
                overflow -= duration
            else:
                element.duration.quarterLength = max(0.125, duration - overflow)
                overflow = 0.0


def _normalize_part_grid(part_stream, grid: str) -> None:
    """Force a strict per-part rhythmic grid and bar duration conformance."""
    from music21 import meter, stream

    divisor = _grid_to_divisor(grid)
    with warnings.catch_warnings():
        _suppress_known_music21_warnings()
        part_stream.makeMeasures(inPlace=True)
    part_stream.quantize(
        quarterLengthDivisors=(divisor,),
        processOffsets=True,
        processDurations=True,
        inPlace=True,
        recurse=True,
    )
    _flatten_part_to_primary_voice(part_stream)
    _rebalance_measure_durations(part_stream)
    measures = list(part_stream.recurse().getElementsByClass(stream.Measure))
    if measures:
        ts = measures[0].getTimeSignatures(returnDefault=True)
        if not ts:
            measures[0].insert(0, meter.TimeSignature("4/4"))


def _align_score_measures(score_obj) -> None:
    """Apply shared measure timeline across all parts for full-score barline alignment."""
    from music21 import meter, note, stream

    with warnings.catch_warnings():
        _suppress_known_music21_warnings()
        score_obj.makeMeasures(inPlace=True)

    max_count = 0
    for part in score_obj.parts:
        measures = list(part.recurse().getElementsByClass(stream.Measure))
        max_count = max(max_count, len(measures))

    if max_count == 0:
        return

    for part in score_obj.parts:
        measures = list(part.recurse().getElementsByClass(stream.Measure))
        if measures:
            sigs = measures[0].getTimeSignatures(returnDefault=True)
            ts = sigs[0] if sigs else meter.TimeSignature("4/4")
            bar_q = float(ts.barDuration.quarterLength)
        else:
            ts = meter.TimeSignature("4/4")
            bar_q = 4.0

        for idx in range(len(measures), max_count):
            extra = stream.Measure(number=(idx + 1))
            if idx == 0:
                extra.insert(0, ts)
            extra.insert(0, note.Rest(quarterLength=bar_q))
            part.append(extra)

        _flatten_part_to_primary_voice(part)
        _rebalance_measure_durations(part)


def _pad_parts_to_common_length(score_obj, grid: str) -> None:
    """Pad shorter parts to shared highestTime before global measure pass."""
    from music21 import note

    parts = list(score_obj.parts)
    if not parts:
        return
    grid_step = {"1/4": 1.0, "1/8": 0.5, "1/16": 0.25}.get(str(grid), 0.5)
    max_time = max(float(part.highestTime or 0.0) for part in parts)
    max_time = round(max_time / grid_step) * grid_step
    for part in parts:
        current = round(float(part.highestTime or 0.0) / grid_step) * grid_step
        deficit = max_time - current
        if deficit > 1e-6:
            part.append(note.Rest(quarterLength=deficit))


def _beginner_playability_thresholds(instrument_name: str) -> dict[str, float]:
    """Return beginner gate thresholds tuned by instrument family."""
    name = str(instrument_name or "")
    strict_melody_tokens = ("Flute", "Clarinet", "Sax", "Trumpet", "Horn", "Oboe")
    lower_voice_tokens = ("Tuba", "Trombone", "Euphonium", "Bassoon", "Bass Clarinet")

    if any(token in name for token in strict_melody_tokens):
        return {"accidental_density": 0.24, "large_leap_rate": 0.34, "short_note_rate": 0.45}
    if any(token in name for token in lower_voice_tokens):
        return {"accidental_density": 0.33, "large_leap_rate": 0.42, "short_note_rate": 0.54}
    return {"accidental_density": 0.30, "large_leap_rate": 0.40, "short_note_rate": 0.50}


def assess_song_fit(midis: dict[str, str], assignment: dict[str, str]) -> dict:
    """Assess transcription feasibility from assigned melodic MIDI parts.

    Returns a dict with:
    - fit_score (0-100)
    - fit_label (Good Fit / Borderline / Poor Fit)
    - recommended_profile (Beginner / Easy Intermediate)
    - reasons (plain-language list)
    - part_metrics (per melodic part metrics)
    """
    from music21 import converter

    percussion_tokens = ("Snare", "Bass Drum", "Percussion", "Auxiliary", "Timpani")
    part_metrics: list[dict] = []

    for stem_name, midi_path in midis.items():
        instrument_name = str(assignment.get(stem_name, "") or "").strip()
        if not instrument_name:
            continue
        if any(token in instrument_name for token in percussion_tokens):
            continue
        midi_file = Path(midi_path)
        if not midi_file.exists():
            continue

        with warnings.catch_warnings():
            _suppress_known_music21_warnings()
            parsed = converter.parse(str(midi_file))
        part_stream = parsed.parts[0] if parsed.parts else parsed
        metrics = _playability_metrics(part_stream)
        note_elements = list(part_stream.recurse().notes)
        chord_count = sum(1 for item in note_elements if getattr(item, "isChord", False))
        bucket_counts: dict[int, int] = {}
        for item in note_elements:
            try:
                offset = float(item.getOffsetInHierarchy(part_stream))
            except Exception:
                continue
            # 1/16-note buckets to estimate overlap/noise density
            bucket = int(round(offset / 0.25))
            bucket_counts[bucket] = bucket_counts.get(bucket, 0) + 1
        overlap_buckets = sum(1 for value in bucket_counts.values() if value > 1)
        total_buckets = max(1, len(bucket_counts))
        metrics["chord_rate"] = float(chord_count / max(1, len(note_elements)))
        metrics["overlap_rate"] = float(overlap_buckets / total_buckets)
        metrics["name"] = instrument_name
        part_metrics.append(metrics)

    if not part_metrics:
        return {
            "fit_score": 25,
            "fit_label": "Poor Fit",
            "recommended_profile": "Easy Intermediate",
            "reasons": [
                "No clear melodic parts were detected from current assignments.",
                "Try different stem assignments or a cleaner source file.",
            ],
            "part_metrics": [],
        }

    total_notes = sum(float(item["note_count"]) for item in part_metrics)
    if total_notes <= 0:
        total_notes = float(len(part_metrics))

    weighted_accidental = sum(
        float(item["accidental_density"]) * float(item["note_count"]) for item in part_metrics
    ) / total_notes
    weighted_leaps = sum(
        float(item["large_leap_rate"]) * float(item["note_count"]) for item in part_metrics
    ) / total_notes
    weighted_short = sum(
        float(item["short_note_rate"]) * float(item["note_count"]) for item in part_metrics
    ) / total_notes
    weighted_chord = sum(
        float(item.get("chord_rate", 0.0)) * float(item["note_count"]) for item in part_metrics
    ) / total_notes
    weighted_overlap = sum(
        float(item.get("overlap_rate", 0.0)) * float(item["note_count"]) for item in part_metrics
    ) / total_notes
    sparse_parts = sum(1 for item in part_metrics if float(item["note_count"]) < 24)
    sparse_rate = sparse_parts / max(1, len(part_metrics))

    # Heavier weight on transcription stability/coverage, lighter on student playability.
    penalty = (
        (weighted_overlap * 34.0)
        + (weighted_chord * 26.0)
        + (sparse_rate * 24.0)
        + (weighted_short * 8.0)
        + (weighted_accidental * 4.0)
        + (weighted_leaps * 4.0)
    )
    fit_score = int(max(0, min(100, round(100.0 - penalty))))

    if fit_score >= 70:
        fit_label = "Good Fit"
    elif fit_score >= 45:
        fit_label = "Borderline"
    else:
        fit_label = "Poor Fit"

    if fit_label == "Poor Fit":
        recommended_profile = "Beginner"
    else:
        recommended_profile = "Easy Intermediate"

    reasons: list[str] = []
    if sparse_rate >= 0.4:
        reasons.append("Some assigned melodic parts are sparse, which can reduce transcription reliability.")
    if weighted_overlap >= 0.22:
        reasons.append("Frequent overlapping note attacks suggest noisy or unstable transcription output.")
    if weighted_chord >= 0.16:
        reasons.append("High stacked-note density suggests harmonic bleed in monophonic lines.")
    if weighted_short >= 0.55:
        reasons.append("Very dense short-note activity may indicate noisy transcription artifacts.")
    if weighted_accidental >= 0.35:
        reasons.append("High accidental density may indicate key ambiguity in detected melody.")
    if weighted_leaps >= 0.50:
        reasons.append("Large jump frequency is elevated and may signal unstable pitch tracking.")
    if sparse_rate >= 0.5:
        reasons.append("Try alternative stem-to-instrument assignments for cleaner melodic extraction.")
    if not reasons:
        reasons.append("Assigned stems look feasible for clean transcription and score generation.")

    return {
        "fit_score": fit_score,
        "fit_label": fit_label,
        "recommended_profile": recommended_profile,
        "reasons": reasons,
        "part_metrics": part_metrics,
    }


def build_score(
    midis: dict[str, str], assignment: dict[str, str], options: dict,
    run_dir: Path | None = None,
) -> dict[str, str | dict[str, str]]:
    """Build concert-pitch full score and transposed individual part MusicXML files.

    Returns dict with keys:
        "full_score": path to concert-pitch MusicXML
        "parts": dict mapping part_name -> transposed part MusicXML path
    """
    import copy

    from music21 import clef, converter, expressions, instrument, interval, metadata, stream

    _ensure_dirs()
    workdir = run_dir or TEMP_DIR
    score = stream.Score(id="btt-score")
    score.metadata = metadata.Metadata()
    score.metadata.title = options.get("title", "Untitled")
    score.metadata.composer = options.get("composer", "")

    disclaimer = create_disclaimer_text(options.get("school", ""))
    simplify_enabled = bool(options.get("simplify_enabled", False))

    part_dir = workdir / "part_exports"
    part_dir.mkdir(parents=True, exist_ok=True)
    transposed_parts: dict[str, str] = {}
    skipped_parts: list[dict] = []
    instrument_counts: dict[str, int] = {}
    percussion_family_tokens = ("Snare", "Bass Drum", "Percussion", "Auxiliary")
    treble_family_tokens = (
        "Flute",
        "Oboe",
        "Clarinet",
        "Sax",
        "Trumpet",
        "Horn",
        "Mallets",
        "Timpani",
    )
    bass_family_tokens = ("Tuba", "Trombone", "Bassoon", "Euphonium")

    def _preferred_clef_for_instrument(name: str):
        if any(token in name for token in percussion_family_tokens):
            return clef.PercussionClef()
        if any(token in name for token in bass_family_tokens):
            return clef.BassClef()
        if any(token in name for token in treble_family_tokens):
            return clef.TrebleClef()
        return None

    def _apply_instrument_and_clef(part_obj, name: str) -> None:
        # MIDI imports may include many embedded instrument-change markers.
        # Normalize to exactly one instrument at offset 0 for clean engraving.
        for existing_instrument in list(part_obj.recurse().getElementsByClass(instrument.Instrument)):
            try:
                existing_instrument.activeSite.remove(existing_instrument)
            except Exception:
                pass
        try:
            part_obj.insert(0, instrument.fromString(name))
        except Exception:
            pass
        preferred = _preferred_clef_for_instrument(name)
        if preferred is not None:
            for existing in list(part_obj.recurse().getElementsByClass(clef.Clef)):
                try:
                    existing.activeSite.remove(existing)
                except Exception:
                    pass
            part_obj.insert(0, preferred)

    for stem_name, midi_path in midis.items():
        instrument_name = assignment.get(stem_name, "").strip()
        if not instrument_name:
            continue

        # Disambiguate when multiple stems share the same instrument
        instrument_counts[instrument_name] = instrument_counts.get(instrument_name, 0) + 1
        count = instrument_counts[instrument_name]
        part_label = instrument_name if count == 1 else f"{instrument_name} ({count})"

        parsed = converter.parse(midi_path)
        part_stream = parsed.parts[0] if parsed.parts else parsed
        original_part_stream = copy.deepcopy(part_stream)
        part_stream.partName = part_label
        part_stream.partAbbreviation = part_label

        if simplify_enabled:
            _simplify_part(part_stream, options)
            if _is_percussion_target(instrument_name):
                _sanitize_percussion_part(part_stream, options)
            elif _is_woodwind_target(instrument_name):
                _sanitize_woodwind_melody(part_stream, instrument_name, options)
            elif _is_low_brass_target(instrument_name):
                _sanitize_single_line_part(part_stream, instrument_name, options)
            if _is_woodwind_target(instrument_name) or _is_percussion_target(instrument_name) or _is_low_brass_target(instrument_name):
                _tighten_monophonic_timeline(part_stream, str(options.get("quantize_grid", "1/8")))

            if len(list(part_stream.recurse().notes)) == 0:
                # Fallback for over-pruned streams:
                # re-run cleanup from original MIDI content with gentler defaults.
                part_stream = copy.deepcopy(original_part_stream)
                relaxed = dict(options)
                relaxed["quantize_grid"] = "1/8"
                relaxed["min_note_duration_beats"] = min(
                    0.25, float(options.get("min_note_duration_beats", 0.25))
                )
                relaxed["density_threshold"] = max(
                    8, int(options.get("density_threshold", 6))
                )
                if _is_percussion_target(instrument_name):
                    _sanitize_percussion_part(part_stream, relaxed)
                elif _is_woodwind_target(instrument_name):
                    _sanitize_woodwind_melody(part_stream, instrument_name, relaxed)
                elif _is_low_brass_target(instrument_name):
                    _sanitize_single_line_part(part_stream, instrument_name, relaxed)
                if _is_woodwind_target(instrument_name) or _is_percussion_target(instrument_name) or _is_low_brass_target(instrument_name):
                    _tighten_monophonic_timeline(part_stream, str(relaxed.get("quantize_grid", "1/8")))

            if _is_woodwind_target(instrument_name) or _is_percussion_target(instrument_name):
                _normalize_part_grid(part_stream, str(options.get("quantize_grid", "1/8")))
            else:
                _flatten_part_to_primary_voice(part_stream)
                _rebalance_measure_durations(part_stream)
            if _is_beginner_profile(options) and not any(
                token in instrument_name for token in ("Snare", "Bass Drum", "Percussion")
            ):
                metrics = _apply_beginner_melody_filter(part_stream)
                limits = _beginner_playability_thresholds(instrument_name)
                if (
                    metrics["note_count"] > 0
                    and (
                        metrics["accidental_density"] > limits["accidental_density"]
                        or metrics["large_leap_rate"] > limits["large_leap_rate"]
                        or metrics["short_note_rate"] > limits["short_note_rate"]
                    )
                ):
                    skipped_parts.append(
                        {
                            "name": part_label,
                            "status": "skipped",
                            "reason": "unplayable_beginner",
                            "note_count": 0,
                        }
                    )
                    continue

        # Concert-pitch copy for the full score
        concert_part = copy.deepcopy(part_stream)
        if _is_percussion_target(instrument_name):
            _force_fixed_percussion_pitch(concert_part, "C5")
        elif _is_woodwind_target(instrument_name):
            _insert_guarded_key_signature(concert_part)
        _apply_instrument_and_clef(concert_part, instrument_name)
        score.insert(0, concert_part)

        # Transposed copy for the individual part export
        semitones = int(INSTRUMENT_SPECS.get(instrument_name, 0))
        transposed_part = copy.deepcopy(part_stream)
        if semitones:
            transposed_part.transpose(interval.Interval(semitones), inPlace=True)
        _clamp_written_part_range(transposed_part, instrument_name)
        if _is_percussion_target(instrument_name):
            _force_fixed_percussion_pitch(transposed_part, "C5")
        elif _is_woodwind_target(instrument_name):
            _insert_guarded_key_signature(transposed_part)
        _apply_instrument_and_clef(transposed_part, instrument_name)
        if _is_woodwind_target(instrument_name) or _is_percussion_target(instrument_name):
            _normalize_part_grid(transposed_part, str(options.get("quantize_grid", "1/8")))
        else:
            _flatten_part_to_primary_voice(transposed_part)
            _rebalance_measure_durations(transposed_part)
        with warnings.catch_warnings():
            _suppress_known_music21_warnings()
            transposed_part = transposed_part.makeNotation(inPlace=False)
        if _is_woodwind_target(instrument_name) or _is_percussion_target(instrument_name):
            _normalize_part_grid(transposed_part, str(options.get("quantize_grid", "1/8")))
        else:
            _flatten_part_to_primary_voice(transposed_part)
            _rebalance_measure_durations(transposed_part)

        part_export_score = stream.Score(id=f"part-{sanitize_filename(part_label)}")
        part_export_score.metadata = metadata.Metadata()
        part_export_score.metadata.title = options.get("title", "Untitled")
        part_export_score.metadata.composer = options.get("composer", "")
        part_export_score.insert(0, transposed_part)

        part_xml = part_dir / f"{sanitize_filename(part_label)}.musicxml"
        part_export_score.write("musicxml", fp=str(part_xml))
        transposed_parts[part_label] = str(part_xml)

    if not score.parts:
        raise RuntimeError("No assigned parts produced notes. Check assignments and inputs.")

    if disclaimer:
        score.insert(0, expressions.TextExpression(disclaimer))
    _pad_parts_to_common_length(score, str(options.get("quantize_grid", "1/8")))
    _align_score_measures(score)
    with warnings.catch_warnings():
        _suppress_known_music21_warnings()
        score = score.makeNotation(inPlace=False)
    _pad_parts_to_common_length(score, str(options.get("quantize_grid", "1/8")))
    _align_score_measures(score)
    with warnings.catch_warnings():
        _suppress_known_music21_warnings()
        score = score.makeNotation(inPlace=False)
    full_score_path = workdir / f"{sanitize_filename(options.get('title', 'score'))}.musicxml"
    score.write("musicxml", fp=str(full_score_path))
    return {"full_score": str(full_score_path), "parts": transposed_parts, "skipped_parts": skipped_parts}


def render_pdfs(score_data: dict[str, str | dict[str, str]], run_id: str | None = None) -> dict:
    """Render full-score PDF (concert pitch) and transposed part PDFs via MuseScore CLI.

    Args:
        score_data: dict from build_score with keys "full_score" and "parts".

    Returns dict with keys:
        "paths": list of rendered PDF file paths
        "part_report": list of dicts with part status details for QC/manifest
    """
    from music21 import converter

    _ensure_dirs()

    full_score_xml = Path(score_data["full_score"])
    if not full_score_xml.exists():
        raise FileNotFoundError(f"Full score MusicXML not found: {full_score_xml}")

    output_root = OUTPUT_DIR / sanitize_filename(run_id) if run_id else OUTPUT_DIR
    output_root.mkdir(parents=True, exist_ok=True)

    score_pdf = output_root / f"{full_score_xml.stem}_full_score.pdf"
    _run([MUSESCORE_CMD, "-o", str(score_pdf), str(full_score_xml)])
    rendered: list[str] = [str(score_pdf)]
    part_report: list[dict] = []
    for item in score_data.get("skipped_parts", []) if isinstance(score_data, dict) else []:
        if isinstance(item, dict):
            part_report.append(
                {
                    "name": str(item.get("name", "")),
                    "status": "skipped",
                    "reason": str(item.get("reason", "unknown")),
                    "note_count": int(item.get("note_count", 0)),
                }
            )

    for part_name, part_xml_path in score_data["parts"].items():
        part_xml = Path(part_xml_path)
        if not part_xml.exists():
            part_report.append({
                "name": part_name, "status": "skipped",
                "reason": "missing_musicxml", "note_count": 0,
            })
            continue

        with warnings.catch_warnings():
            _suppress_known_music21_warnings()
            parsed_part = converter.parse(str(part_xml))
        note_count = len(list(parsed_part.recurse().notes))

        if note_count == 0:
            part_report.append({
                "name": part_name, "status": "skipped",
                "reason": "no_notes", "note_count": 0,
            })
            continue

        part_pdf = output_root / f"{sanitize_filename(part_name)}.pdf"
        _run([MUSESCORE_CMD, "-o", str(part_pdf), str(part_xml)])
        rendered.append(str(part_pdf))
        part_report.append({
            "name": part_name, "status": "exported",
            "note_count": note_count, "path": str(part_pdf),
        })

    if len(rendered) == 1:
        raise RuntimeError("No non-empty parts were rendered.")
    return {"paths": rendered, "part_report": part_report}
